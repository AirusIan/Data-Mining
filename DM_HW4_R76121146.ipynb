{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 以下是Equal-Width"
      ],
      "metadata": {
        "id": "MDQNoFZo7na1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2f04F4x7gs-"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from collections import Counter\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_lists = 11\n",
        "with open('glass.txt', 'r') as file:\n",
        "    # 创建空列表以存储结果\n",
        "    org_lists = [[] for _ in range(number_of_lists)]  # number_of_lists是您想要创建的列表数量\n",
        "\n",
        "    # 逐行读取文件中的数据\n",
        "    for line in file:\n",
        "        # 去除行末的换行符并按逗号分割数据\n",
        "        data = line.strip().split(',')\n",
        "\n",
        "        # 将每个数据按照其在行中的位置存入相应的列表\n",
        "        for index, value in enumerate(data):\n",
        "            org_lists[index].append(float(value))"
      ],
      "metadata": {
        "id": "EO5I244s7yPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rows = list(zip(*org_lists))\n",
        "\n",
        "# 對行進行 shuffle\n",
        "random.shuffle(rows)\n",
        "\n",
        "# 再次使用 zip 將行轉換為列\n",
        "shuffled_data = list(zip(*rows))\n",
        "\n",
        "# 打印洗牌後的資料\n",
        "for row in shuffled_data:\n",
        "    print(row)"
      ],
      "metadata": {
        "id": "O9uHQFE_fvEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "org_lists = shuffled_data"
      ],
      "metadata": {
        "id": "9yTG8VEKg4Er"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#捨棄第一個Column\n",
        "lists = []\n",
        "for i, data_list in enumerate(org_lists):\n",
        "  if i == 0 :\n",
        "    continue\n",
        "  else:\n",
        "    lists.append(list(data_list))"
      ],
      "metadata": {
        "id": "KQZp3fyA8CoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_bins = 10\n",
        "\n",
        "# 存储每个bin的分割点\n",
        "bin_edges = []\n",
        "\n",
        "# 对每个列表进行处理\n",
        "for lst in lists:\n",
        "    # 找到最小值和最大值，以确定bin的范围\n",
        "    min_val = min(lst)\n",
        "    max_val = max(lst)\n",
        "\n",
        "    # 计算bin的宽度\n",
        "    bin_width = (max_val - min_val) / num_bins\n",
        "\n",
        "    # 生成每个bin的分割点\n",
        "    bin_edges.append([min_val + i * bin_width for i in range(1,num_bins)])\n",
        "equal_wid_list = []\n",
        "# 将每个值替换为所属的bin的编号\n",
        "for i, lst in enumerate(lists):\n",
        "    if i == 9:\n",
        "      continue\n",
        "    bin_edge = bin_edges[i]\n",
        "    discrete_attri = [0] * len(lst)\n",
        "    for j, value in enumerate(lst):\n",
        "        if(lists[i][j] >= bin_edge[len(bin_edge)-1]):\n",
        "          discrete_attri[j] = len(bin_edge)+1\n",
        "          continue\n",
        "        for k in range(0, len(bin_edge)):\n",
        "            if value <= bin_edge[k]:\n",
        "                discrete_attri[j] = k+1\n",
        "                break\n",
        "    equal_wid_list.append(discrete_attri)\n",
        "    print(f'List {i+1} : {lists[i]}')\n",
        "    print(f'Split Point{bin_edge}')\n",
        "    print(\"Atrribute after discretization:\", discrete_attri)\n",
        "    print()\n",
        "equal_wid_list.append(lists[9])"
      ],
      "metadata": {
        "id": "yDMGBz9Q8L3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, data_list in enumerate(equal_wid_list):\n",
        "  for c in range(len(data_list)):\n",
        "    data_list[c] = str(data_list[c])\n",
        "  print(f'List {i}: {data_list}')\n",
        "  print(len(data_list))"
      ],
      "metadata": {
        "id": "W3kMTp4t8OsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# 假設這是你的資料，每一個元素是一個 column\n",
        "data = [\n",
        "    [1, 'a', True],\n",
        "    [2, 'b', False],\n",
        "    [3, 'c', True],\n",
        "    [4, 'd', False]\n",
        "]\n",
        "\n",
        "# 使用 zip 將列轉換為行\n",
        "rows = list(zip(*data))\n",
        "\n",
        "# 對行進行 shuffle\n",
        "random.shuffle(rows)\n",
        "\n",
        "# 再次使用 zip 將行轉換為列\n",
        "shuffled_data = list(zip(*rows))\n",
        "\n",
        "# 打印洗牌後的資料\n",
        "for row in shuffled_data:\n",
        "    print(row)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "D90aHye0ha_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''#Shuffle\n",
        "rows = list(zip(*equal_wid_list))\n",
        "\n",
        "# 對行進行 shuffle\n",
        "random.shuffle(rows)\n",
        "\n",
        "# 再次使用 zip 將行轉換為列\n",
        "shuffled_data = list(zip(*rows))\n",
        "\n",
        "# 打印洗牌後的資料\n",
        "for row in shuffled_data:\n",
        "    print(row)'''"
      ],
      "metadata": {
        "id": "EPw79oCgkMUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_size = 43\n",
        "testlist = equal_wid_list[0]\n",
        "chunked_list = [testlist[i:i + chunk_size] for i in range(0, len(testlist), chunk_size)]\n",
        "\n",
        "# 將這些小list存在一個新的list中\n",
        "result_list = chunked_list\n",
        "for i,data_list in enumerate(result_list):\n",
        "  print(f'i {i}: len: {len(data_list)} :{data_list}')\n"
      ],
      "metadata": {
        "id": "FrpjkJ_H8rrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_size = 43\n",
        "equal_wid_list_for5 = []\n",
        "for i, data_list in enumerate(equal_wid_list):\n",
        "  tmplist = equal_wid_list[i]\n",
        "  chunked_list = [tmplist[i:i + chunk_size] for i in range(0, len(tmplist), chunk_size)]\n",
        "  equal_wid_list_for5.append(chunked_list)\n",
        "\n"
      ],
      "metadata": {
        "id": "S4lFcTHVGk6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, data_list in enumerate(equal_wid_list_for5):\n",
        "  print(f'i{i} {data_list}')"
      ],
      "metadata": {
        "id": "_-y-tUPxHS7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 假設你有一個包含許多列表的列表，例如：\n",
        "testlist = [[1,2,3],[4,5,6],[7,8,9]]\n",
        "skip_index = 0  # 替換成你想要跳過的列表的索引\n",
        "\n",
        "# 使用列表理解式將剩下的列表連接成一個新的列表\n",
        "test_list = testlist[skip_index]\n",
        "train_list = [item for i, sublist in enumerate(testlist) if i != skip_index for item in sublist]\n",
        "\n",
        "print(f'test_list {test_list} train_list {train_list}')\n",
        "print(type(test_list))\n"
      ],
      "metadata": {
        "id": "-8YYgGTxPZRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testlist = equal_wid_list_for5[0]\n",
        "skip_index = 2  # 替換成你想要跳過的列表的索引\n",
        "\n",
        "# 使用列表理解式將剩下的列表連接成一個新的列表\n",
        "test_list = testlist[skip_index]\n",
        "train_list = [item for i, sublist in enumerate(testlist) if i != skip_index for item in sublist]\n",
        "\n",
        "print(f'test_list {test_list} train_list {train_list}')"
      ],
      "metadata": {
        "id": "WOHZLIHmRI_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def kcross(skip_idx, target_list):\n",
        "  test_set=[]\n",
        "  train_set=[]\n",
        "  for i in range(0,10):\n",
        "    test_list = target_list[i][skip_idx]\n",
        "    test_set.append(list(test_list))\n",
        "    train_list = [item for i, sublist in enumerate(target_list[i]) if i != skip_idx for item in sublist]\n",
        "    train_set.append(train_list)\n",
        "  return test_set, train_set"
      ],
      "metadata": {
        "id": "0Exv7VVOk-t_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t1, r1 = kcross(0, equal_wid_list_for5)\n"
      ],
      "metadata": {
        "id": "z7Eln6hLmgHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i,data_list in enumerate(t1):\n",
        "  print(f'{i} {data_list} {len(data_list)} {type(data_list)}')"
      ],
      "metadata": {
        "id": "UZu8Gk_vnSrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i,data_list in enumerate(r1):\n",
        "  print(f'{i} {data_list} {len(data_list)} {type(data_list)}')"
      ],
      "metadata": {
        "id": "_sb_x9sxpY29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nj(target_list, class_num):\n",
        "  last_list = target_list[9]\n",
        "  num_nj = [0] * 7\n",
        "  for i in last_list:\n",
        "    if i == '1.0':\n",
        "      num_nj[0] += 1\n",
        "    elif i == '2.0':\n",
        "      num_nj[1] += 1\n",
        "    elif i == '3.0':\n",
        "      num_nj[2] += 1\n",
        "    elif i == '4.0':\n",
        "      num_nj[3] += 1\n",
        "    elif i == '5.0':\n",
        "      num_nj[4] += 1\n",
        "    elif i == '6.0':\n",
        "      num_nj[5] += 1\n",
        "    elif i == '7.0':\n",
        "      num_nj[6] += 1\n",
        "  return num_nj[class_num-1]"
      ],
      "metadata": {
        "id": "VnCY-fTh9U95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nj(r1, 7)"
      ],
      "metadata": {
        "id": "z4K5QypAFB4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ki(target_list,col):\n",
        "  knum = set()\n",
        "  attri = target_list[col]\n",
        "  #attri = selected_lists[col]\n",
        "  for i in range(0,len(attri)):\n",
        "    knum.add(attri[i])\n",
        "\n",
        "  return len(knum)"
      ],
      "metadata": {
        "id": "LxlSgrOqFjVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ki(r1, 7)"
      ],
      "metadata": {
        "id": "cjuLppirFugC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nij(target_list, numofdata, column, class_num, values):\n",
        "  count = 0\n",
        "  #values = target_list[column][numofdata]\n",
        "  for i in range(0,len(target_list[0])):\n",
        "    if(target_list[len(target_list)-1][i] == class_num and target_list[column][i] == values):\n",
        "      count += 1\n",
        "  return count"
      ],
      "metadata": {
        "id": "sKgoETbnG06M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nij(r1,0,3,'1.0',2 )"
      ],
      "metadata": {
        "id": "pbziwZpIHQiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Laplace(target_list, row, column, class_num, values):\n",
        "  nij_val = nij(target_list, row, column, str(float((class_num))), values)\n",
        "  nj_val = nj(target_list, class_num)\n",
        "  k_val = ki(target_list, column)\n",
        "  nij_val += 1\n",
        "  #print(f'nij_val {nij_val} nj_val {nj_val} k_val {k_val}')\n",
        "  return nij_val / (nj_val + k_val)"
      ],
      "metadata": {
        "id": "89XPQenQHV_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Laplace(r1, 0,1,6,3)"
      ],
      "metadata": {
        "id": "7n1wT10OHe6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,5):\n",
        "  testing_set, training_set = kcross(i, equal_wid_list_for5)\n",
        "  corr = 0\n",
        "  for u in range(0, len(testing_set[0])):\n",
        "    c_star = -1\n",
        "    highest_likelihood = -1\n",
        "    for j in range(1,8):\n",
        "      likelihood = nj(training_set, j)/len(training_set[0])\n",
        "      for x in range(0,9):\n",
        "        xi = testing_set[x][u]\n",
        "        likelihood *= Laplace(training_set, u, x, j, xi)\n",
        "\n",
        "      if likelihood > highest_likelihood:\n",
        "        highest_likelihood = likelihood\n",
        "        c_star = j\n",
        "    if str(float(c_star)) == testing_set[9][u]:\n",
        "        corr += 1\n",
        "  print(f'Fold {i+1} Correct num: {corr} Wrong num: {len(testing_set[0])-corr} Accuracy: {corr/len(testing_set[0])}')\n"
      ],
      "metadata": {
        "id": "dskau65NHwin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 以下是Equal-Frequency"
      ],
      "metadata": {
        "id": "j0pySUEDaiVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#捨棄第一個Column\n",
        "lists = []\n",
        "for i, data_list in enumerate(org_lists):\n",
        "  if i == 0 :\n",
        "    continue\n",
        "  else:\n",
        "    lists.append(list(data_list))"
      ],
      "metadata": {
        "id": "GVw6y-KLan4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_bins = 10\n",
        "# 初始化分割点列表\n",
        "equal_freq_list = []\n",
        "# 对每个列表进行处理\n",
        "k = int(len(lists[0]) / 10)\n",
        "for i in range(len(lists)):\n",
        "    if i == 9:\n",
        "      continue\n",
        "    # 对列表进行排序\n",
        "    sorted_lst = sorted(lists[i])\n",
        "    split_pts = []\n",
        "    # 计算每个bin的大小\n",
        "    bin_size = len(lists[i]) // num_bins\n",
        "    # 计算分割点\n",
        "    for j in range(1, 10):\n",
        "        split_point_index = (sorted_lst[j*k] + sorted_lst[j*k+1])/2\n",
        "        if split_point_index not in split_pts:#確保分割點不重複\n",
        "          split_pts.append(split_point_index)\n",
        "    # 将每个值替换为所属的bin的编号\n",
        "    bin_indices = [0] * len(lists[i])\n",
        "\n",
        "    for z in range(0,len(lists[i])):\n",
        "        #bigthanlast = 1 #比最後一個分割點還大\n",
        "        if lists[i][z] > split_pts[len(split_pts)-1]:\n",
        "          bin_indices[z] = len(split_pts)+1\n",
        "          continue\n",
        "        for u in range(0,len(split_pts)+1):\n",
        "            if lists[i][z] <= split_pts[u]:\n",
        "                bin_indices[z] = u+1\n",
        "                #bigthanlast = 0\n",
        "                break\n",
        "        '''if bigthanlast == 1:\n",
        "              bin_indices[z] = len(split_pts)+1'''\n",
        "    equal_freq_list.append(bin_indices)\n",
        "    print(f'List {i+1}: {lists[i]}')\n",
        "    print(\"Split Points:\", split_pts)\n",
        "    print(\"Bin Indices:\", bin_indices)\n",
        "    print()\n",
        "equal_freq_list.append(lists[9])"
      ],
      "metadata": {
        "id": "bfkK5gpEb9u7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, data_list in enumerate(equal_freq_list):\n",
        "  for c in range(len(data_list)):\n",
        "    data_list[c] = str(data_list[c])\n",
        "  print(f'List {i+1}: {data_list}')"
      ],
      "metadata": {
        "id": "3RdgCKkOjhGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_size = 43\n",
        "equal_freq_list_for5 = []\n",
        "for i, data_list in enumerate(equal_freq_list):\n",
        "  tmplist = equal_freq_list[i]\n",
        "  chunked_list = [tmplist[i:i + chunk_size] for i in range(0, len(tmplist), chunk_size)]\n",
        "  equal_freq_list_for5.append(chunked_list)"
      ],
      "metadata": {
        "id": "gfPlqJ-5nu01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,5):\n",
        "  testing_set, training_set = kcross(i, equal_freq_list_for5)\n",
        "  corr = 0\n",
        "  for u in range(0, len(testing_set[0])):\n",
        "    c_star = -1\n",
        "    highest_likelihood = -1\n",
        "    for j in range(1,8):\n",
        "      likelihood = nj(training_set, j)/len(training_set[0])\n",
        "      for x in range(0,9):\n",
        "        xi = testing_set[x][u]\n",
        "        likelihood *= Laplace(training_set, u, x, j, xi)\n",
        "\n",
        "      if likelihood > highest_likelihood:\n",
        "        highest_likelihood = likelihood\n",
        "        c_star = j\n",
        "    if str(float(c_star)) == testing_set[9][u]:\n",
        "        corr += 1\n",
        "  print(f'Fold {i+1} Correct num {corr} Wrong num {len(testing_set[0])-corr} Accuracy: {corr/len(testing_set[0])}')"
      ],
      "metadata": {
        "id": "KJVDm5knovR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 以下是Entropy-Based"
      ],
      "metadata": {
        "id": "plB-Dvmk6bkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#捨棄第一個Column\n",
        "lists = []\n",
        "for i, data_list in enumerate(org_lists):\n",
        "  if i == 0 :\n",
        "    continue\n",
        "  else:\n",
        "    lists.append(list(data_list))"
      ],
      "metadata": {
        "id": "e8_11pLN6glq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "biggest_list = []\n",
        "last_list = lists[-1]\n",
        "# 对每个列表进行处理\n",
        "for lst in lists:\n",
        "  big_list = []\n",
        "  for i in range(len(lst)):\n",
        "    new_list = [lst[i], last_list[i]]  # 创建new_list，第一个值是第一个元素，第二个值是最后一个元素\n",
        "    big_list.append(new_list)  # 创建big_list，将new_list添加进去\n",
        "  biggest_list.append(big_list)  # 将big_list添加到biggest_list中\n",
        "\n",
        "# 打印结果\n",
        "for i, big_list in enumerate(biggest_list):\n",
        "    print(f\"biggest_list[{i+1}]: {big_list}\")"
      ],
      "metadata": {
        "id": "zxdqdOxH6qPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sort_by_first_element(new_list):\n",
        "    return new_list[0]\n",
        "result_list = []\n",
        "for big_list in biggest_list:\n",
        "    sorted_big_list = sorted(big_list, key=sort_by_first_element)\n",
        "    result_list.append(sorted_big_list)\n",
        "    print(sorted_big_list)\n",
        "result_list = result_list[:-1]"
      ],
      "metadata": {
        "id": "PcU4RlEl6v7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Entropy(d_list, x, y):\n",
        "  # 初始化一个列表，用于存储在指定范围内的第二个值\n",
        "  values_in_range = []\n",
        "  # 遍历 d_list 中的索引范围 [x, y]\n",
        "  for i in range(x, y+1):\n",
        "      temp_list = d_list[i]\n",
        "      second_value = temp_list[1]\n",
        "      values_in_range.append(second_value)\n",
        "\n",
        "  # 使用 Counter 统计值的出现频率\n",
        "  value_counts = Counter(values_in_range)\n",
        "\n",
        "  # 计算熵\n",
        "  total_count = len(values_in_range)\n",
        "  entropy = 0.0\n",
        "  for count in value_counts.values():\n",
        "      probability = count / total_count\n",
        "      entropy -= probability * math.log(probability, 2)\n",
        "  return entropy"
      ],
      "metadata": {
        "id": "7Hqccp-V7XEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def kclass_num(d_list, x, y):\n",
        "  # 初始化一个列表，用于存储在指定范围内的第二个值\n",
        "  knum = set()\n",
        "  # 遍历 d_list 中的索引范围 [x, y]\n",
        "  for i in range(x, y+1):\n",
        "      temp_list = d_list[i]\n",
        "      second_value = temp_list[1]\n",
        "      knum.add(second_value)\n",
        "\n",
        "  return len(knum)"
      ],
      "metadata": {
        "id": "Necg61wk7ZHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CheckCutPoint(x, y, d_list, split_ps):\n",
        "  if(x == y):\n",
        "    return\n",
        "  min_cut_value = 99999\n",
        "  cutpoint = -1\n",
        "  total_entropy = Entropy(d_list, x, y)\n",
        "  N = y - x + 1\n",
        "  for i in range(x, y):\n",
        "    S1_len = i - x + 1\n",
        "    S2_len = y - i + 1\n",
        "    left_entropy = Entropy(d_list, x, i)\n",
        "    right_entropy = Entropy(d_list, i+1, y)\n",
        "    if (S1_len / N * left_entropy + S2_len / N * right_entropy) < min_cut_value:\n",
        "      min_cut_value = (S1_len / N * left_entropy + S2_len / N * right_entropy)\n",
        "      cutpoint = i\n",
        "  S1_len = cutpoint - x + 1\n",
        "  S2_len = y - cutpoint + 1\n",
        "  left_entropy = Entropy(d_list, x, cutpoint)\n",
        "  right_entropy = Entropy(d_list, cutpoint+1, y)\n",
        "  k = kclass_num(d_list, x, y)\n",
        "  k1 = kclass_num(d_list, x, cutpoint+1)\n",
        "  k2 = kclass_num(d_list, cutpoint+1, y)\n",
        "\n",
        "  Gain = total_entropy - (S1_len / N * left_entropy + S2_len / N * right_entropy)\n",
        "  delta = math.log2(N-1) / N + ( math.log2(3**k-2) - (k*total_entropy - k1*left_entropy -k2*right_entropy))/N\n",
        "  print(f'x {x} cutpoint {cutpoint} y {y}')\n",
        "  print(f'Gain {Gain} delta {delta}')\n",
        "  print()\n",
        "\n",
        "  if Gain > delta:\n",
        "    if d_list[cutpoint][0] not in split_ps:\n",
        "      split_ps.append((d_list[cutpoint][0]+d_list[cutpoint+1][0])/2)\n",
        "    CheckCutPoint(x, cutpoint, d_list, split_ps)\n",
        "    CheckCutPoint(cutpoint+1, y, d_list, split_ps)\n",
        "  else:\n",
        "    return"
      ],
      "metadata": {
        "id": "e5HiGNr97c8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_split_ps = []\n",
        "for i, d_list in enumerate(result_list):\n",
        "  split_ps = []\n",
        "  CheckCutPoint(0, 212, d_list, split_ps)\n",
        "  all_split_ps.append(split_ps)\n",
        "#all_split_ps[8].clear()"
      ],
      "metadata": {
        "id": "6-7P7pNV7eoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i,d_lst in enumerate(all_split_ps):\n",
        "  d_lst = sorted(d_lst)\n",
        "  print(f'List {i+1} split points{d_lst}')"
      ],
      "metadata": {
        "id": "Mj3ptkrI7jVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 初始化分割点列表\n",
        "entropy_based_list = []\n",
        "# 对每个列表进行处理\n",
        "k = int(len(lists[0]) / 10)\n",
        "for i in range(len(lists)):\n",
        "    if i == 9:\n",
        "      continue\n",
        "\n",
        "    split_pts = sorted(all_split_ps[i])\n",
        "    # 将每个值替换为所属的bin的编号\n",
        "    bin_indices = [1] * len(lists[i])\n",
        "\n",
        "    for z in range(0,len(lists[i])):\n",
        "        if len(split_pts) == 0:\n",
        "          continue\n",
        "        if lists[i][z] > split_pts[len(split_pts)-1]:\n",
        "          bin_indices[z] = len(split_pts)+1\n",
        "          continue\n",
        "        for u in range(0,len(split_pts)):\n",
        "            if lists[i][z] <= split_pts[u]:\n",
        "                bin_indices[z] = u+1\n",
        "                break\n",
        "    entropy_based_list.append(bin_indices)\n",
        "    print(f'List {i+1}: {lists[i]}')\n",
        "    print(\"Split Points:\", split_pts)\n",
        "    print(\"Bin Indices:\", bin_indices)\n",
        "    print()\n",
        "entropy_based_list.append(lists[9])"
      ],
      "metadata": {
        "id": "MjLxD0N78Q3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, data_list in enumerate(entropy_based_list):\n",
        "  for c in range(len(data_list)):\n",
        "    data_list[c] = str(data_list[c])\n",
        "  print(f'List {i+1}: {data_list}')"
      ],
      "metadata": {
        "id": "OEjxxdU4-RYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_size = 43\n",
        "entropy_based_list_for5 = []\n",
        "for i, data_list in enumerate(entropy_based_list):\n",
        "  tmplist = entropy_based_list[i]\n",
        "  chunked_list = [tmplist[i:i + chunk_size] for i in range(0, len(tmplist), chunk_size)]\n",
        "  entropy_based_list_for5.append(chunked_list)"
      ],
      "metadata": {
        "id": "O0iMMjNs8zFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,5):\n",
        "  testing_set, training_set = kcross(i, entropy_based_list_for5)\n",
        "  corr = 0\n",
        "  for u in range(0, len(testing_set[0])):\n",
        "    c_star = -1\n",
        "    highest_likelihood = -1\n",
        "    for j in range(1,8):\n",
        "      likelihood = nj(training_set, j)/len(training_set[0])\n",
        "      for x in range(0,9):\n",
        "        xi = testing_set[x][u]\n",
        "        likelihood *= Laplace(training_set, u, x, j, xi)\n",
        "\n",
        "      if likelihood > highest_likelihood:\n",
        "        highest_likelihood = likelihood\n",
        "        c_star = j\n",
        "    if str(float(c_star)) == testing_set[9][u]:\n",
        "        corr += 1\n",
        "  print(f'Fold {i+1} Correct num {corr} Wrong num {len(testing_set[0])-corr} Accuracy: {corr/len(testing_set[0])}')"
      ],
      "metadata": {
        "id": "0jJT-yt887-S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}